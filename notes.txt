* mouse position is wrong in fullscreen mode

* the numbering of the naming of the circle images is backwards i think. neg1 should swap with 1 etc

* try erode / dilute in gimp.  Not sure how to do the "even brightness" thing the paper talks about though.
 * need a new crosshatch texture

* fix seams in whatever of the cross hatching textures have them. (is it due to triplanar? could try changing the axes!)
 * and/or get/make better textures!
 * i think that is just where the texture edge is and that the texture isn't a very good tileable texture.

* try some minor optimizations to see if they help much. (write details in notes for blog post i guess)
 * N samples per call, instead of just the 1.  may decrease time spent on (texture) memory read / write?
 * bounding volume (box? sphere?) as pre-test for rays for meshes.

! for color cross hatching, try YCoCg-R instead of YUV? https://en.wikipedia.org/wiki/YCoCg
 * maybe make "full brightness" be based on albedo somehow? even though it's not... shrug

* need to figure out how to process the cross hatching textures. dilation filter, even color texture etc.
 * eventually write code that does this, or figure out steps in gimp.

? should source crosshatching textures be single channel? maybe doesn't matter that much. Only really care for perf / efficiency.

* color crosshatching:
 * convert to hue / brightness. hue is tint for texture, brightness selects texture
 * could also try using texture as a lerp value between a light and dark color

* Models at turbosquid! https://www.turbosquid.com/
 * and unity store
 * and here: https://github.com/movAX13h/HiOctaneTools/tree/master/Unpacked%20Assets/models
 * if using those high octane assets, need to texture them with atlas.png i think.

* get some fun models to use for testing, make some fun scenes.
* make it use textures for shading - using the color to tint the non black parts of the textures.

? why triplanar uv's? if you already have UV coordinates you could use those and do fewer texture reads!

? have c++ side send an iterative sum of golden ratio to shader?
 * or try just adding the random number per frame to it!
  * i tried that and it looked aweful, maybe my prng sucks with seeds that are in 0-1?
 * try and see if you can keep the seed in 0-1?
 * if this works out get rid of app rand and frame number and app time i think.
 ! i tried this 8/29 at lunch and it didn't work out, not sure what the problem is.
 * white noise is probably better over area and time since you are doing more samples not fewer

* bayesian integration would probably be better here since there's no specular. but there is occlusion so...
 * dunno how bayesian integration works. would be good to learn but maybe out of scope

! the path on cornell box has red wall on left, but the "showpathtrace" flips it correctly to red wall on right. should fix that minor wrinkle

! need to keep the rng seed from becoming so huge that small floats don't matter and it stops updating.

be able to move camera? reset sample count on camera move. WASD + mouse look.


TODO's in code

Sean said he'd be willing to give me textures.
 * how bout models?


* make it spit out shader-error.txt even if there are just warnings?

* could also directly sample the light to make it converge faster (i think you should, if it's unbiased!)

* will eventually want to make videos probably. A thing to render a frame at a time and then use ffmpeg to combine? Would need logic for updating camera and objects over time. Fixed frame rate update obviously!

* could have a bounding shape on "instanced meshes" which if the ray hits, gives a start/stop triangle index range to test ray against.
 * could also possibly have a scale, translation, rotation for instance.
 * try only if actually needed.

* get rid of unused models and textures when done

* add russian roulette to the path tracing? https://computergraphics.stackexchange.com/questions/2316/is-russian-roulette-really-the-answer
 * lets you get the benefits of more bounces without paying the full cost and doesn't add bias

? could try jittering the first hit. anti alias may be fine shrug.

* could try hard coding the scenes by writing functions to test intersection with them into shader files that are included
 * may increase perf, not sure.

 * somehow there are leaks (d3d11 warning of live objects) on shutdown

================================= LATER IDEAS =================================

* could do a lens and get depth of field effect. (actually, won't work with this technique).. or will it? why wouldn't it work? (oh... trilinear mapping. would need to do lens flare as a post process!)
* reflections. Probably needs to be done as a post step, but could do N samples and jitter them even.
* anti aliasing? could render at 4x resolution and downsample final image (longer to render though)
* caustics and refraction could be interesting
* Work with sean for the franklin booth technioque?

================================= HIGH LEVEL GOALS =================================

1) path trace diffuse / emissive of a scene with a mesh. (monochromatic?)
2) use the brightness values to determine which tileable crosshatching texture to use (trilinear filtering w/ volume texture)
3) success!
4) maybe multiple scenes and some debug displays and such. (IMGUI? Or rely on renderdoc?)

================================= NOTES =================================

DX11 guide: http://www.rastertek.com/dx11tut02.html

* when writing a CPU path tracer, each time i needed a random number, i just called rand() basically. very easy.
 * on gpu, not so easy to generate random numbers! (could show problems of doign it incorrectly)
 * ended up using a blue noise texture as initial seed, and adding frame number * golden ratio to make it a low discrepancy sequence over time.

* free blue nois textures: http://momentsingraphics.de/?p=127

* tiny obj loader: https://github.com/syoyo/tinyobjloader

* a similar, interesting technique: http://www.floored.com/blog/2014sketch-rendering/

* imgui: https://github.com/ocornut/imgui

@Jontology - saw some screenshots of my "stuck" results and had some ideas of what was going wrong.
* unreal: https://github.com/JonGreenberg/Crosshatching
