* black lines went away, but the cornel box thing on the back wall is still there, what's that about?

! fix the black line on quad tests.
 * the dark line down the middle of the scene in SphereOnPlane_LowLight stays there if all there is, is the ground, and the light sphere.
* something is wrong with one of the tests. maybe ray vs triangle. it has the black line in the center.
 * could also be a problem w/ hemisphere sampling maybe.

* get rid of depth, depth test, and back face culling
 * i don't think we need a depth buffer since it'll all be path traced, so remove that (eventually)

* check out todo's here. if nothing pressing, get model loading / rendering working? bounding spheres (?) around triangles? or just triangle soup.

? have c++ side send an iterative sum of golden ratio to shader?
 * or try just adding the random number per frame to it!
  * i tried that and it looked aweful, maybe my prng sucks with seeds that are in 0-1?
 * try and see if you can keep the seed in 0-1?
 * if this works out get rid of app rand and frame number and app time i think.
 ! i tried this 8/29 at lunch and it didn't work out, not sure what the problem is.

! need to keep the rng seed from becoming so huge that small floats don't matter and it stops updating.

? try using a low discrepancy sequence instead of random number generator? you do over time but maybe also try over space? or maybe sample a blue noise texture for initial seed?
 * yes, this!
 * tile a blue noise texture as initial seed. add framenumber * golden ratio to seed each frame. do you frac result?

allow a way to specify screen w/h and fullscreen. Command line? or just leave it like it is.

show fps / mspf

test x64 and release

TODO's in code

Sean said he'd be willing to give me textures.

? I'm thinking we probably want window borders / close button on this window.

* make it spit out shader-error.txt even if there's just warnings?

* could also directly sample the light to make it converge faster

* will eventually want to make videos probably. A thing to render a frame at a time and then use ffmpeg to combine? Would need logic for updating camera and objects over time. Fixed frame rate update obviously!

? HDR to SDR tone mapping?

================================= LATER IDEAS =================================

* could do a lens and get depth of field effect. (actually, won't work with this technique)
* reflections. Probably needs to be done as a post step, but could do N samples and jitter them even.
* anti aliasing? could render at 4x resolution and downsample final image (longer to render though)
* caustics and refraction could be interesting
* Work with sean for the franklin booth technioque?

================================= HIGH LEVEL GOALS =================================

1) path trace diffuse / emissive of a scene with a mesh. (monochromatic?)
2) use the brightness values to determine which tileable crosshatching texture to use (trilinear filtering w/ volume texture)
3) success!
4) maybe multiple scenes and some debug displays and such. (IMGUI? Or rely on renderdoc?)

================================= NOTES =================================

DX11 guid: http://www.rastertek.com/dx11tut02.html

* when writing a CPU path tracer, each time i needed a random number, i just called rand() basically. very easy.
 * on gpu, not so easy to generate random numbers! (could show problems of doign it incorrectly)
 * ended up using a blue noise texture as initial seed, and adding frame number * golden ratio to make it a low discrepancy sequence over time.

* free blue nois textures: http://momentsingraphics.de/?p=127